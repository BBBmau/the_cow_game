name: PR Pod Environment Management

on:
  pull_request:
    types: [opened, synchronize, reopened, closed]

permissions:
  contents: read
  issues: write
  pull-requests: write

env:
  PROJECT_ID: thecowgame
  REGION: us-west1
  REGISTRY: us-west1-docker.pkg.dev

jobs:
  build-image:
    if: github.event.action != 'closed'
    runs-on: ubuntu-latest
    outputs:
      image-sha: ${{ steps.build.outputs.image-sha }}
    
    steps:
    - name: Checkout
      uses: actions/checkout@v4

    - name: Authenticate to Google Cloud
      uses: google-github-actions/auth@v2
      with:
        credentials_json: ${{ secrets.GCP_SA_KEY }}
        project_id: ${{ env.PROJECT_ID }}

    - name: Configure Docker for GCR
      run: gcloud auth configure-docker ${{ env.REGISTRY }}

    - name: Build and push Docker image
      id: build
      run: |
        IMAGE_SHA=$(echo ${{ github.sha }} | cut -c1-7)
        IMAGE_TAG="${{ env.REGISTRY }}/${{ env.PROJECT_ID }}/game-images/mmo-server:${IMAGE_SHA}"
        
        docker build -t $IMAGE_TAG .
        docker push $IMAGE_TAG
        
        echo "image-sha=${IMAGE_SHA}" >> $GITHUB_OUTPUT

  deploy-pr-pods:
    if: github.event.action != 'closed'
    needs: build-image
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout
      uses: actions/checkout@v4

    - name: Authenticate to Google Cloud
      uses: google-github-actions/auth@v2
      with:
        credentials_json: ${{ secrets.GCP_SA_KEY }}
        project_id: ${{ env.PROJECT_ID }}

    - name: Get GKE credentials
      run: |
        gcloud container clusters get-credentials the-cow-game-cluster --region=${{ env.REGION }}

    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v2
      with:
        terraform_version: 1.5.0

    - name: Terraform Init
      working-directory: ./infra/pr-pods
      run: terraform init

    - name: Create or select workspace
      working-directory: ./infra/pr-pods
      run: |
        WORKSPACE_NAME="pr-${{ github.event.number }}"
        terraform workspace select $WORKSPACE_NAME || terraform workspace new $WORKSPACE_NAME

    - name: Create Terraform variables file
      working-directory: ./infra/pr-pods
      run: |
        cat > terraform.tfvars <<EOF
        project_id = "${{ env.PROJECT_ID }}"
        region = "${{ env.REGION }}"
        image_sha = "${{ needs.build-image.outputs.image-sha }}"
        environment = "pr-${{ github.event.number }}"
        pr_number = "${{ github.event.number }}"
        EOF

    - name: Terraform Plan
      working-directory: ./infra/pr-pods
      run: terraform plan -out=tfplan

    - name: Terraform Apply
      working-directory: ./infra/pr-pods
      run: terraform apply tfplan

    - name: Get deployment info
      id: get-info
      run: |
        # Write outputs directly using predictable names
        echo "gameserver-deployment=cow-game-pr-${{ github.event.number }}-server" >> $GITHUB_OUTPUT
        echo "redis-deployment=cow-game-pr-${{ github.event.number }}-redis" >> $GITHUB_OUTPUT  
        echo "gameserver-service=cow-game-pr-${{ github.event.number }}-server" >> $GITHUB_OUTPUT
        
        # Get load balancer IP using kubectl instead of terraform output to avoid debug info
        SERVICE_NAME="cow-game-pr-${{ github.event.number }}-server"
        LB_IP=$(kubectl get service $SERVICE_NAME -o jsonpath='{.status.loadBalancer.ingress[0].ip}' 2>/dev/null || echo "pending")
        
        # If IP is empty, set to pending
        if [ -z "$LB_IP" ] || [ "$LB_IP" = "null" ]; then
          LB_IP="pending"
        fi
        
        echo "load-balancer-ip=${LB_IP}" >> $GITHUB_OUTPUT

    - name: Comment PR (Initial)
      id: initial-comment
      uses: actions/github-script@v6
      with:
        script: |
          const prNumber = context.payload.number;
          const imagesha = "${{ needs.build-image.outputs.image-sha }}";
          const gameserverDeployment = "${{ steps.get-info.outputs.gameserver-deployment }}";
          const redisDeployment = "${{ steps.get-info.outputs.redis-deployment }}";
          const gameserverService = "${{ steps.get-info.outputs.gameserver-service }}";
          const loadBalancerIP = "${{ steps.get-info.outputs.load-balancer-ip }}";
          
          const accessSection = loadBalancerIP === "pending" ? 
            "ğŸ”„ **Status:** LoadBalancer IP is being assigned... (will update this comment when ready)" : 
            `ğŸŒ **Game URL:** http://${loadBalancerIP}\nğŸ® **Game Server:** ${loadBalancerIP}:6060`;
          
          const body = "## ğŸš€ PR Environment Deployed Successfully!\n\n" +
            "| **Parameter** | **Value** |\n" +
            "|---------------|-----------|\n" +
            `| ğŸ·ï¸ **Environment** | \`pr-${prNumber}\` |\n` +
            `| ğŸ‹ **Image SHA** | \`${imagesha}\` |\n` +
            `| ğŸ“… **Deployed** | ${new Date().toLocaleString()} |\n\n` +
            "### ğŸŒ Access Your Environment\n" +
            accessSection + "\n\n" +
            "---\n\n" +
            "### ğŸ“¦ Resources Created\n" +
            `- ğŸ® **Game Server Deployment:** \`${gameserverDeployment}\`\n` +
            `- ğŸ—„ï¸ **Redis Deployment:** \`${redisDeployment}\`\n` +
            `- âš–ï¸ **Load Balancer:** \`${gameserverService}\`\n\n` +
            "### ğŸ” Monitoring Commands\n" +
            "```bash\n" +
            "# Check deployment status\n" +
            `kubectl get deployments -l pr-number=${prNumber}\n\n` +
            "# Check pod status\n" +
            `kubectl get pods -l pr-number=${prNumber}\n\n` +
            "# Check service status\n" +
            `kubectl get services -l pr-number=${prNumber}\n\n` +
            "# View game server logs\n" +
            `kubectl logs deployment/${gameserverDeployment} -f\n\n` +
            "# View Redis logs\n" +
            `kubectl logs deployment/${redisDeployment} -f\n` +
            "```\n\n" +
            "### ğŸ¯ Testing Your Changes\n" +
            "1. Navigate to the game URL above\n" +
            "2. Test your PR changes in the isolated environment\n" +
            "3. Check logs for any issues\n\n" +
            "---\n" +
            "<sub>ğŸ’¡ This environment will be automatically cleaned up when the PR is closed/merged</sub>";
          
          const comment = await github.rest.issues.createComment({
            issue_number: prNumber,
            owner: context.repo.owner,
            repo: context.repo.repo,
            body: body
          });
          
          return comment.data.id;

    - name: Wait for LoadBalancer IP and Update Comment
      if: steps.get-info.outputs.load-balancer-ip == 'pending'
      uses: actions/github-script@v6
      with:
        script: |
          const prNumber = context.payload.number;
          const imagesha = "${{ needs.build-image.outputs.image-sha }}";
          const gameserverDeployment = "${{ steps.get-info.outputs.gameserver-deployment }}";
          const redisDeployment = "${{ steps.get-info.outputs.redis-deployment }}";
          const gameserverService = "${{ steps.get-info.outputs.gameserver-service }}";
          const commentId = ${{ steps.initial-comment.outputs.result }};
          
          // Wait for LoadBalancer IP with timeout
          let loadBalancerIP = "pending";
          const maxAttempts = 12; // 6 minutes total (30s * 12)
          
          for (let attempt = 1; attempt <= maxAttempts; attempt++) {
            console.log(`Attempt ${attempt}/${maxAttempts}: Checking LoadBalancer IP...`);
            
            try {
              const { exec } = require('child_process');
              const util = require('util');
              const execAsync = util.promisify(exec);
              
              const { stdout } = await execAsync(`kubectl get service ${gameserverService} -o jsonpath='{.status.loadBalancer.ingress[0].ip}'`);
              const ip = stdout.trim();
              
              if (ip && ip !== 'null' && ip !== '') {
                loadBalancerIP = ip;
                console.log(`LoadBalancer IP found: ${loadBalancerIP}`);
                break;
              }
            } catch (error) {
              console.log(`Error checking LoadBalancer: ${error.message}`);
            }
            
            if (attempt < maxAttempts) {
              console.log('IP not ready yet, waiting 30 seconds...');
              await new Promise(resolve => setTimeout(resolve, 30000));
            }
          }
          
          // Update the comment with final status
          const accessSection = loadBalancerIP === "pending" ? 
            "âš ï¸ **Status:** LoadBalancer IP assignment timed out. Please check manually:\n```bash\nkubectl get service " + gameserverService + " -o jsonpath='{.status.loadBalancer.ingress[0].ip}'\n```" : 
            `ğŸŒ **Game URL:** http://${loadBalancerIP}\nğŸ® **Game Server:** ${loadBalancerIP}:6060`;
          
          const updatedBody = "## ğŸš€ PR Environment Deployed Successfully!\n\n" +
            "| **Parameter** | **Value** |\n" +
            "|---------------|-----------|\n" +
            `| ğŸ·ï¸ **Environment** | \`pr-${prNumber}\` |\n` +
            `| ğŸ‹ **Image SHA** | \`${imagesha}\` |\n` +
            `| ğŸ“… **Deployed** | ${new Date().toLocaleString()} |\n` +
            `| ğŸŒ **IP Ready** | ${loadBalancerIP === "pending" ? "â° Timed out" : "âœ… " + new Date().toLocaleString()} |\n\n` +
            "### ğŸŒ Access Your Environment\n" +
            accessSection + "\n\n" +
            "---\n\n" +
            "### ğŸ“¦ Resources Created\n" +
            `- ğŸ® **Game Server Deployment:** \`${gameserverDeployment}\`\n` +
            `- ğŸ—„ï¸ **Redis Deployment:** \`${redisDeployment}\`\n` +
            `- âš–ï¸ **Load Balancer:** \`${gameserverService}\`\n\n` +
            "### ğŸ” Monitoring Commands\n" +
            "```bash\n" +
            "# Check deployment status\n" +
            `kubectl get deployments -l pr-number=${prNumber}\n\n` +
            "# Check pod status\n" +
            `kubectl get pods -l pr-number=${prNumber}\n\n` +
            "# Check service status\n" +
            `kubectl get services -l pr-number=${prNumber}\n\n` +
            "# View game server logs\n" +
            `kubectl logs deployment/${gameserverDeployment} -f\n\n` +
            "# View Redis logs\n" +
            `kubectl logs deployment/${redisDeployment} -f\n` +
            "```\n\n" +
            "### ğŸ¯ Testing Your Changes\n" +
            "1. Navigate to the game URL above\n" +
            "2. Test your PR changes in the isolated environment\n" +
            "3. Check logs for any issues\n\n" +
            "---\n" +
            "<sub>ğŸ’¡ This environment will be automatically cleaned up when the PR is closed/merged</sub>";
          
          await github.rest.issues.updateComment({
            owner: context.repo.owner,
            repo: context.repo.repo,
            comment_id: commentId,
            body: updatedBody
          });
          
          console.log(`Comment updated with LoadBalancer IP: ${loadBalancerIP}`);

  cleanup-pr-pods:
    if: github.event.action == 'closed'
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout
      uses: actions/checkout@v4

    - name: Authenticate to Google Cloud
      uses: google-github-actions/auth@v2
      with:
        credentials_json: ${{ secrets.GCP_SA_KEY }}
        project_id: ${{ env.PROJECT_ID }}

    - name: Get GKE credentials
      run: |
        gcloud container clusters get-credentials the-cow-game-cluster --region=${{ env.REGION }}

    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v2
      with:
        terraform_version: 1.5.0

    - name: Terraform Init
      working-directory: ./infra/pr-pods
      run: terraform init

    - name: Create Terraform variables file
      working-directory: ./infra/pr-pods
      run: |
        cat > terraform.tfvars <<EOF
        project_id = "${{ env.PROJECT_ID }}"
        region = "${{ env.REGION }}"
        image_sha = "cleanup"
        environment = "pr-${{ github.event.number }}"
        pr_number = "${{ github.event.number }}"
        EOF

    - name: Select workspace and destroy
      working-directory: ./infra/pr-pods
      run: |
        WORKSPACE_NAME="pr-${{ github.event.number }}"
        if terraform workspace select $WORKSPACE_NAME; then
          terraform destroy -auto-approve
          
          terraform workspace select default
          terraform workspace delete $WORKSPACE_NAME
        else
          echo "Workspace pr-${{ github.event.number }} not found, nothing to clean up"
        fi

    - name: Comment PR
      uses: actions/github-script@v6
      with:
        script: |
          const prNumber = context.payload.number;
          
          github.rest.issues.createComment({
            issue_number: prNumber,
            owner: context.repo.owner,
            repo: context.repo.repo,
            body: `ğŸ§¹ **PR Pod Environment Cleaned Up!**
            
            **Environment:** \`pr-${prNumber}\`
            **Status:** All pods and services destroyed
            
            The following resources have been removed:
            - Game Server Pod: \`cow-game-pr-${prNumber}-server\`
            - Redis Pod: \`cow-game-pr-${prNumber}-redis\`
            - Associated services and LoadBalancer
            `
          }); 
